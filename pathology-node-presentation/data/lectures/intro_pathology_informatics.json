{
  "meta": {
    "title": "Pathology Informatics for Residents: Logic, Workflow, and the Future of Practice",
    "shortTitle": "Introduction to Pathology Informatics",
    "presenter": "Peter Gershkovich, MD. MHA",
    "institution": "Yale University School of Medicine",
    "date": "2025",
    "theme": {
      "primary": "#1e3a5f",
      "secondary": "#2980b9",
      "accent": "#27ae60"
    }
  },
  "slides": [
    {
      "id": "title",
      "type": "title",
      "transition": "zoom",
      "title": "Pathology Informatics for Residents",
      "subtitle": "Logic, Workflow, and the Future of Practice",
      "presenter": "Peter Gershkovich, MD. MHA",
      "institution": "Yale University School of Medicine",
      "date": "2025"
    },

    {
      "id": "hook",
      "type": "content",
      "transition": "fade",
      "badge": "workflow",
      "title": "You Already Do Informatics Every Day",
      "bullets": [
        "Case assembly and \"what belongs together\"",
        "Stain ordering logic (rules + exceptions)",
        "Report distribution (who must know, when)",
        "Amendments (error detection + correction propagation)"
      ],
      "takeaway": "The clinical work is inseparable from information flow."
    },

    {
      "id": "poll-systems",
      "type": "poll",
      "transition": "fade",
      "title": "Poll: Where Do Systems Help vs Hurt You?",
      "prompt": "Where do your current systems most help — and most hurt — your work? (click to tally responses)",
      "options": [
        "Accessioning / specimen labeling",
        "Grossing / cassette & block tracking",
        "Slide ordering / special stains",
        "Case assembly / worklists",
        "Reporting / synoptics",
        "Distribution / communication",
        "Amendments / corrections",
        "QA / peer review / conference prep"
      ],
      "note": "Save results — we'll revisit the top pain points later."
    },

    {
      "id": "informatics-vs-it",
      "type": "two-column",
      "transition": "fade",
      "title": "Informatics vs IT",
      "left": {
        "heading": "Informatics",
        "bullets": [
          "Designs information structures + workflows to improve outcomes",
          "Optimizes the \"human + system\" loop",
          "Clinical logic made operational"
        ]
      },
      "right": {
        "heading": "IT",
        "bullets": [
          "Operates infrastructure, security, devices, networks",
          "Installs, maintains, ensures uptime",
          "Keeps the plumbing running"
        ]
      },
      "takeaway": "Informatics = clinical logic made operational. IT = infrastructure. Both essential — different jobs."
    },

    {
      "id": "abstraction-analogy",
      "type": "visualization",
      "transition": "slide",
      "badge": "workflow",
      "title": "The Car Analogy: Focus on the Right Abstraction Layer",
      "subtitle": "You don't need to understand the chipset — focus on the logic layer where clinical value lives.",
      "vizType": "abstraction-layers",
      "takeaway": "Focus on workflow logic and decision layers — not CPU architecture. That's where clinical value lives."
    },

    {
      "id": "thesis",
      "type": "content",
      "transition": "fade",
      "title": "Thesis: Logical Problems > Technical Problems",
      "subtitle": "Most pathology \"informatics pain\" is not CPU/bandwidth — it's model mismatch.",
      "bullets": [
        "Wrong recipient gets a report → workflow logic + metadata failure",
        "Laterality discrepancy slips through → validation logic gap",
        "\"Completed\" status ≠ clinically ready → semantic mismatch",
        "Synoptic structure doesn't match real-world exceptions → representation mismatch",
        "System supports \"workflow\" but not how people <em>actually</em> work → reality mismatch"
      ]
    },

    {
      "id": "objectives",
      "type": "content",
      "transition": "fade",
      "title": "Learning Objectives",
      "numberedItems": [
        "Describe lab workflow as a system of <strong>events and decisions</strong>",
        "Explain why automation should <strong>reduce cognitive load</strong>, not create it",
        "Identify how <strong>data representation and quality</strong> drive safety, analytics, and AI performance",
        "Understand how <strong>LLMs and computer vision AI</strong> are reshaping pathology practice",
        "Ask better questions of vendors/IT: <em>\"show me how exceptions work\"</em>"
      ]
    },

    {
      "id": "workflow-definition",
      "type": "content",
      "transition": "fade",
      "badge": "workflow",
      "title": "What \"Workflow\" Means in the Lab",
      "subtitle": "The chain of tasks and events that creates clinical value.",
      "bullets": [
        "\"Workflow is why your day feels smooth or chaotic\"",
        "It is the substrate on which everything else depends — data, automation, AI",
        "Good workflow design: invisible. Bad workflow design: constant friction"
      ],
      "takeaway": "Workflow is the substrate on which everything else (data, automation, AI) depends."
    },

    {
      "id": "three-phases",
      "type": "visualization",
      "transition": "fade",
      "badge": "workflow",
      "title": "Three-Phase View: Pre-Analytical → Analytical → Post-Analytical",
      "vizType": "workflow-pipeline",
      "takeaway": "Sets up systematic thinking about where failures occur."
    },

    {
      "id": "microcase-delay",
      "type": "micro-case",
      "transition": "fade",
      "title": "Micro-Case: Where Did the Delay Happen?",
      "scenario": "A surgical pathology case is flagged as \"late.\" You have timestamps across the system but no clear cause. The clinician is frustrated. Where do you look first?",
      "options": ["Pre-analytical", "Analytical", "Post-analytical"],
      "discussion": [
        "Systems often measure the wrong step → wrong intervention",
        "\"Visibility\" is the first step toward improvement",
        "TAT metrics without phase attribution are nearly useless",
        "The fix might be organizational, not technical"
      ]
    },

    {
      "id": "ap-workflow-steps",
      "type": "content",
      "transition": "fade",
      "badge": "workflow",
      "title": "AP Workflow Steps Residents Should Recognize",
      "bullets": [
        "Intake / accession",
        "Grossing",
        "Histology (processing, embedding, cutting, staining)",
        "Slide logistics & case assembly",
        "Sign-out (primary diagnosis)",
        "Amendments & addenda",
        "Consults & second opinions",
        "Reporting distribution & notifications"
      ],
      "takeaway": "A \"case\" is an evolving object; systems must track state changes, not just snapshots."
    },

    {
      "id": "workarounds",
      "type": "content",
      "transition": "fade",
      "badge": "workflow",
      "title": "The \"Gap\": Why Workarounds Appear",
      "subtitle": "Requirements evolve; closed systems don't → gap → workarounds.",
      "bullets": [
        "Shadow spreadsheets for tracking",
        "\"Please ignore the LIS status\"",
        "Manual copy/paste and duplicate data entry",
        "People becoming the integration layer",
        "Sticky notes on monitors as the real workflow engine"
      ],
      "takeaway": "Workarounds are not \"user failure\" — they're system design evidence."
    },

    {
      "id": "wf-management",
      "type": "content",
      "transition": "fade",
      "badge": "workflow",
      "title": "What Workflow Management Systems Should Do",
      "bullets": [
        "Track assets and transitions (specimen → blocks → slides → images)",
        "Coordinate humans (handoffs, assignments, escalations)",
        "Identify exceptions (delays, missing steps, mismatches)",
        "Provide meaningful metrics (not vanity timestamps)",
        "Reduce cognitive load and prevent preventable errors"
      ]
    },

    {
      "id": "automate-exercise",
      "type": "timer",
      "transition": "fade",
      "title": "Think–Pair–Share: What Would You Automate Tomorrow?",
      "prompt": "Write one automation you'd implement tomorrow that would make your work safer or faster. Then discuss with a neighbor.",
      "duration": 90,
      "categories": [
        "Workflow orchestration",
        "Data quality / validation",
        "Decision support",
        "Communication / coordination",
        "Governance / compliance"
      ]
    },

    {
      "id": "generic-automation",
      "type": "content",
      "transition": "fade",
      "badge": "automation",
      "title": "The Problem with \"Generic Automation\"",
      "subtitle": "Automation without domain understanding becomes coercion.",
      "bullets": [
        "Forced structured fields that don't match reality → unsafe workarounds",
        "Hard stops that don't understand urgency or context",
        "Status labels that are administratively neat but clinically false",
        "One-size workflows that ignore subspecialty differences"
      ]
    },

    {
      "id": "good-vs-bad-automation",
      "type": "comparison",
      "transition": "fade",
      "badge": "automation",
      "title": "Principle: Automate Repetition, Preserve Judgment",
      "left": {
        "heading": "Good Automation",
        "style": "good",
        "bullets": [
          "Removes repetition",
          "Surfaces exceptions",
          "Helps triage attention",
          "Makes the right action easier than the wrong one"
        ]
      },
      "right": {
        "heading": "Bad Automation",
        "style": "bad",
        "bullets": [
          "Standardizes away nuance",
          "Creates noise and alert fatigue",
          "Forces clinicians to work around the system",
          "Prioritizes administrative neatness over clinical truth"
        ]
      },
      "takeaway": "The goal is not \"more automation\" — it's better logic."
    },

    {
      "id": "automation-ladder",
      "type": "visualization",
      "transition": "fade",
      "badge": "automation",
      "title": "Maturity Ladder: Tracking → Prevention → Guidance",
      "vizType": "automation-ladder",
      "takeaway": "The goal is not \"more automation,\" but better logic at each level."
    },

    {
      "id": "microcase-hardstop",
      "type": "micro-case",
      "transition": "fade",
      "title": "Micro-Case: Hard Stop vs Guardrail?",
      "scenario": "(1) Laterality mismatch, (2) Wrong-site label risk, (3) Missing clinical correlation, (4) Missing CC recipient. What's the right system response for each?",
      "options": ["Block sign-out (hard stop)", "Warn + require acknowledgment (guardrail)", "Silent logging only (audit)"],
      "discussion": [
        "No single answer is always right — context matters",
        "Severity × detectability × context × operational reality",
        "Hard stops are expensive (time, attention, trust erosion)",
        "Silent logging misses the intervention window",
        "Guardrails are often the sweet spot — but require good UX"
      ],
      "discussionFrame": "Framework: Severity × Detectability × Context × Operational Reality"
    },

    {
      "id": "competitive-advantage",
      "type": "content",
      "transition": "fade",
      "badge": "automation",
      "title": "Competitive Advantage (Yes, Even in Academia)",
      "bullets": [
        "<strong>Competitive advantage</strong> = measurable superiority in outcomes, efficiency, reliability, experience",
        "Better workflow + better data → fewer delays, fewer amendments, better service to care teams",
        "Labs that master informatics attract talent and clinical partners",
        "This isn't corporate jargon — it's how departments survive and grow"
      ]
    },

    {
      "id": "data-purpose",
      "type": "content",
      "transition": "fade",
      "badge": "data",
      "title": "Data Exists to Enable Correct Action",
      "subtitle": "Data is fuel for decisions, distribution, analytics, and safety.",
      "bullets": [
        "Every data element should serve a downstream decision",
        "Bad data forces humans to become the integration engine",
        "\"Garbage in, garbage out\" applies to AI even more than to reports"
      ],
      "takeaway": "Bad data forces humans to become the integration engine."
    },

    {
      "id": "structured-unstructured",
      "type": "two-column",
      "transition": "fade",
      "badge": "data",
      "title": "Structured vs Unstructured in AP",
      "left": {
        "heading": "Narrative (Unstructured)",
        "bullets": [
          "Supports nuance and reasoning",
          "Captures uncertainty and context",
          "Natural for pathologist communication",
          "Hard for machines to parse reliably"
        ]
      },
      "right": {
        "heading": "Structured Data",
        "highlight": true,
        "bullets": [
          "Supports computation, QA, registries",
          "Enables staging, coding, research reuse",
          "Required for analytics and AI pipelines",
          "Rigid — may not capture exceptions"
        ]
      },
      "takeaway": "A coherent hybrid model matters more than dogma about structure vs narrative."
    },

    {
      "id": "data-representation",
      "type": "content",
      "transition": "fade",
      "badge": "data",
      "title": "Data Representation: Where Logic Breaks",
      "subtitle": "\"Representation\" = assignment of meaning to artifacts.",
      "bullets": [
        "Synonyms, negations, hedging (\"cannot exclude\")",
        "Specimen naming drift (\"left pelvic node\" vs \"pelvic LN, left\")",
        "Context missing (\"per requisition,\" \"per op note\")",
        "Laterality is present in text but not computable",
        "These aren't edge cases — they're daily occurrences"
      ]
    },

    {
      "id": "data-quality",
      "type": "content",
      "transition": "fade",
      "badge": "data",
      "title": "Data Quality Dimensions (Why Analytics/AI Fail)",
      "bullets": [
        "<strong>Completeness</strong> — are all required fields populated?",
        "<strong>Correctness</strong> — does the data match reality?",
        "<strong>Timeliness</strong> — is it available when needed?",
        "<strong>Consistency</strong> — same concept, same representation?"
      ],
      "note": "Clinical consequences: wrong follow-up, incomplete distribution, missed research cohorts, false alarms, alert fatigue."
    },

    {
      "id": "find-ambiguity",
      "type": "snippets",
      "transition": "fade",
      "title": "Interactive: Find the Ambiguity",
      "snippets": [
        "\"Invasive carcinoma <strong>cannot be excluded</strong> in this limited sample.\"",
        "\"Left? <em>(per requisition)</em>\" — laterality uncertain, documented as given.",
        "Narrative says \"<strong>negative</strong> for malignancy.\" Synoptic field: Tumor Present = <strong>Yes</strong>."
      ],
      "prompt": "What would a system need to <em>know</em> to prevent downstream error in each case?",
      "goal": "Make residents articulate context dependencies explicitly."
    },

    {
      "id": "data-flow",
      "type": "visualization",
      "transition": "fade",
      "badge": "data",
      "title": "Data Flow Lifecycle: Creation → Storage → Use",
      "vizType": "data-flow",
      "takeaway": "Failures cluster at interfaces, not in isolated steps."
    },

    {
      "id": "systems-ecosystem",
      "type": "visualization",
      "transition": "fade",
      "badge": "ecosystem",
      "title": "The Pathology Systems Ecosystem",
      "subtitle": "No single system — pathology runs on an interconnected network.",
      "vizType": "systems-ecosystem",
      "takeaway": "Pathology runs on a network of systems. Integration quality determines clinical quality."
    },

    {
      "id": "stewardship",
      "type": "content",
      "transition": "fade",
      "badge": "ecosystem",
      "title": "Stewardship: Pathologist Responsibility Expands",
      "subtitle": "Laboratory information stewardship = integrity + optimal use of lab data.",
      "bullets": [
        "You may not own IT, but you own the clinical consequences",
        "Configuration decisions shape patient care daily",
        "Who validates that reflex rules fire correctly? Who checks distribution logic?",
        "Stewardship is not optional — it's core competency"
      ],
      "takeaway": "You may not own IT, but you own clinical consequences."
    },

    {
      "id": "governance",
      "type": "content",
      "transition": "fade",
      "badge": "ecosystem",
      "title": "Organizational Reality: Governance and \"Who Decides\"",
      "bullets": [
        "Priorities, configuration decisions, safety constraints, change control",
        "Relationship to CIO/CMIO and institutional standards",
        "Understanding decision pathways prevents years of suffering",
        "The informatics-savvy pathologist has outsized influence here"
      ]
    },

    {
      "id": "config-is-clinical",
      "type": "content",
      "transition": "fade",
      "badge": "ecosystem",
      "title": "Configuration Is Clinical Practice",
      "subtitle": "Not technical preferences — these shape patient care.",
      "bullets": [
        "Ordering catalogs and synonyms",
        "Reflex testing logic",
        "Status definitions and state transitions",
        "Alert thresholds and notification rules",
        "Distribution rules and recipient logic",
        "Access controls and audit strategy"
      ]
    },

    {
      "id": "vendor-questions",
      "type": "workshop",
      "transition": "fade",
      "title": "Workshop: 10 Questions for a New LIS/Vendor",
      "instruction": "Use as an interactive checklist — ask residents to add 2 more.",
      "groups": [
        {
          "heading": "Workflow",
          "items": [
            "\"Show me how exceptions are handled — not the happy path.\"",
            "\"How do you model specimen–part–block–slide relationships?\"",
            "\"How do you handle evolving cases (new stains, rework, addenda)?\""
          ]
        },
        {
          "heading": "Safety",
          "start": 4,
          "items": [
            "\"How do you prevent wrong-patient / wrong-site propagation?\"",
            "\"What is your approach to hard stops vs guardrails?\""
          ]
        },
        {
          "heading": "Data + Analytics",
          "start": 6,
          "items": [
            "\"Can we compute key metrics without custom extracts?\"",
            "\"How do you represent laterality, site, and uncertainty in computable form?\""
          ]
        },
        {
          "heading": "Interop & Usability",
          "start": 8,
          "items": [
            "\"What functions integrate end-to-end, not just export data?\"",
            "\"How do you measure clicks/time-to-complete and reduce cognitive load?\"",
            "\"How quickly can we change configuration safely (change control, validation)?\""
          ]
        }
      ]
    },

    {
      "id": "poll-digital",
      "type": "poll",
      "transition": "fade",
      "title": "Poll: Do You Use Digital Slides Today?",
      "prompt": "What is your current experience with digital pathology?",
      "options": [
        "Primary diagnosis routinely",
        "Occasionally (consults / tumor boards)",
        "Rarely",
        "Never"
      ],
      "note": "We'll tailor the AI discussion based on where the room is."
    },

    {
      "id": "digital-path-infra",
      "type": "content",
      "transition": "fade",
      "badge": "ai",
      "title": "Digital Pathology: Infrastructure Reality",
      "bullets": [
        "<strong>WSI scanners</strong> — high-resolution whole-slide imaging at 40×",
        "<strong>Storage at scale</strong> — terabytes per year; on-prem vs cloud tradeoffs",
        "<strong>Viewers + LIS integration</strong> — the diagnostic interface must be seamless",
        "<strong>\"Digital-first\" vs \"digital-available\"</strong> — different maturity, different challenges",
        "New failure modes: identity management, version control, color calibration, uptime"
      ],
      "takeaway": "Digital pathology is an infrastructure commitment, not just a scanner purchase."
    },

    {
      "id": "computer-vision-ai",
      "type": "content",
      "transition": "fade",
      "badge": "ai",
      "title": "Computer Vision AI in Pathology",
      "bullets": [
        "<strong>What it does:</strong> detection, segmentation, quantification, grading assistance",
        "<strong>FDA-authorized examples:</strong> Paige Prostate (2021) — first AI for pathology, 7.3% improvement in cancer detection",
        "<strong>Key principle:</strong> accuracy alone is insufficient — workflow integration determines clinical value",
        "<strong>Validation burden:</strong> institutions must validate independently, not just trust vendor claims",
        "AI as adjunctive tool: pathologist must review — on-label use matters"
      ]
    },

    {
      "id": "llms-in-pathology",
      "type": "two-column",
      "transition": "fade",
      "badge": "ai",
      "title": "LLMs and Language AI in Pathology",
      "left": {
        "heading": "What LLMs Can Do Today",
        "bullets": [
          "Structured data extraction from narrative reports",
          "Report drafting and synoptic population",
          "Literature summarization and synthesis",
          "Clinical decision support via natural language",
          "NLP on path reports for registry/cohort identification",
          "Automated coding suggestions"
        ]
      },
      "right": {
        "heading": "What They Cannot Do Reliably",
        "highlight": true,
        "bullets": [
          "Replace pathologist judgment",
          "Guarantee factual accuracy (hallucination risk)",
          "Handle novel or rare entities without training data",
          "Understand institutional context and local policies",
          "Self-validate — they don't know what they don't know"
        ]
      },
      "takeaway": "LLMs are powerful text engines — you must understand their failure modes to use them safely."
    },

    {
      "id": "ai-governance",
      "type": "content",
      "transition": "fade",
      "badge": "ai",
      "title": "AI Governance: Who Validates, Who Is Liable?",
      "bullets": [
        "<strong>On-label vs off-label:</strong> using AI outside its approved indication changes the risk profile",
        "<strong>Validation responsibility:</strong> vendor claims ≠ institutional validation — you must verify",
        "<strong>Bias:</strong> training data composition determines performance across demographics and tissue types",
        "<strong>Documentation:</strong> when AI contributes to diagnosis, what goes in the record?",
        "<strong>Stewardship connection:</strong> AI governance is the extension of lab information stewardship"
      ]
    },

    {
      "id": "ai-maturity",
      "type": "visualization",
      "transition": "fade",
      "badge": "ai",
      "title": "The AI Maturity Ladder for Pathology",
      "subtitle": "Parallels the automation maturity ladder — same principle, higher stakes.",
      "vizType": "ai-maturity-ladder",
      "takeaway": "Don't skip levels. Retrospective analytics must work before you trust real-time AI."
    },

    {
      "id": "ai-trust",
      "type": "micro-case",
      "transition": "fade",
      "title": "Interactive: Would You Trust This AI Output?",
      "scenario": "(1) AI flags a prostate biopsy region as suspicious. (2) An LLM drafts a synoptic from your dictation. (3) An algorithm auto-prioritizes your worklist. What's your response?",
      "options": ["Trust and use as-is", "Review and edit", "Reject and redo manually"],
      "discussion": [
        "Context matters: What's the AI's track record? Is it validated here?",
        "Trust calibration: Over-trust is as dangerous as under-trust",
        "Transparency: Can you see WHY the AI made that decision?",
        "Accountability: If the AI is wrong, whose name is on the report?",
        "The answer should almost always involve human review — for now"
      ]
    },

    {
      "id": "cybersecurity",
      "type": "content",
      "transition": "fade",
      "badge": "ecosystem",
      "title": "Cybersecurity + Availability: The Silent Curriculum",
      "bullets": [
        "<strong>Downtime = patient safety event</strong> — not just an inconvenience",
        "Security controls shape access and workflows daily",
        "Auditability and traceability matter (especially with AI outputs)",
        "Ransomware attacks on healthcare systems are increasing yearly",
        "Your downtime procedures are as important as your uptime workflows"
      ],
      "takeaway": "The system must be dependable and accountable."
    },

    {
      "id": "takeaways",
      "type": "takeaways",
      "transition": "fade",
      "title": "Key Takeaways",
      "items": [
        "Informatics is the <strong>logic of clinical work expressed in software</strong> — focus on the abstraction layer that matters, not the chipset.",
        "Good automation <strong>removes repetition and highlights exceptions</strong>; it does not force generic workflows on clinical practice.",
        "Data representation and quality determine <strong>safety, analytics, and AI usefulness</strong> — garbage in, garbage out.",
        "AI tools — whether vision or language — are only as good as their <strong>integration, validation, and governance</strong>."
      ],
      "cta": {
        "label": "Call to action:",
        "text": "Pick one workflow pain point this month. Describe it as: <strong>event → decision → data → consequence</strong>. Send me one \"automation candidate\" and one \"ambiguity\" you've seen."
      }
    },

    {
      "id": "qa",
      "type": "qa",
      "transition": "zoom",
      "title": "Questions & Discussion",
      "contact": "Peter Gershkovich, MD. MHA — Yale University School of Medicine"
    }
  ]
}
